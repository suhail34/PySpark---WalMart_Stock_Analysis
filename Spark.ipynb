{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e0e873",
   "metadata": {},
   "source": [
    "# Initialize a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49155aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/10 21:42:05 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('walmart').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c350a",
   "metadata": {},
   "source": [
    "# Load the Walmart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c783fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./WMT.xls', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d16c70",
   "metadata": {},
   "source": [
    "# Display the Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b804c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c83ef",
   "metadata": {},
   "source": [
    "# Display the first row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fef293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date=datetime.datetime(2011, 11, 16, 0, 0), Open=57.099998, High=57.419998, Low=56.639999, Close=56.68, Adj Close=44.899456, Volume=11780800)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5589a2",
   "metadata": {},
   "source": [
    "# Check the Schema of the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e4084d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbdc30d",
   "metadata": {},
   "source": [
    "# Print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7329cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.datetime(2011, 11, 16, 0, 0), Open=57.099998, High=57.419998, Low=56.639999, Close=56.68, Adj Close=44.899456, Volume=11780800) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 17, 0, 0), Open=56.540001, High=57.189999, Low=56.259998, Close=56.73, Adj Close=44.939064, Volume=10223800) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 18, 0, 0), Open=57.029999, High=57.360001, Low=56.610001, Close=57.23, Adj Close=45.335129, Volume=8982300) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 21, 0, 0), Open=56.93, High=57.290001, Low=56.380001, Close=56.66, Adj Close=44.883606, Volume=9932200) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 22, 0, 0), Open=56.560001, High=57.130001, Low=56.5, Close=56.849998, Adj Close=45.034107, Volume=7497300) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in df.head(5):\n",
    "    print(line, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb1f68",
   "metadata": {},
   "source": [
    "# Print general Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580dfd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------------+------------------+----------------+\n",
      "|summary|              Open|              High|               Low|            Close|         Adj Close|          Volume|\n",
      "+-------+------------------+------------------+------------------+-----------------+------------------+----------------+\n",
      "|  count|              2516|              2516|              2516|             2516|              2516|            2516|\n",
      "|   mean| 90.25209059817178| 90.94377592090628| 89.61924488434002|90.28167732551657| 82.77843126589822|8267158.86327504|\n",
      "| stddev|25.818932768463412|26.070702860968247|25.565153063174236|25.79883827640457|29.207787105719017|4587081.88545677|\n",
      "|    min|         56.389999|              57.0|         56.259998|        56.419998|         44.867764|         2094900|\n",
      "|    max|        153.600006|        153.660004|        151.660004|       152.789993|        151.449997|        80898100|\n",
      "+-------+------------------+------------------+------------------+-----------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a22991c",
   "metadata": {},
   "source": [
    "# Format Columns to show just 2 Decimal Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d02a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+----------+\n",
      "|summary|    Open|    High|     Low|   Close|    Volume|\n",
      "+-------+--------+--------+--------+--------+----------+\n",
      "|  count|2,516.00|2,516.00|2,516.00|2,516.00|     2,516|\n",
      "|   mean|   90.25|   90.94|   89.62|   90.28| 8,267,158|\n",
      "| stddev|   25.82|   26.07|   25.57|   25.80| 4,587,081|\n",
      "|    min|   56.39|   57.00|   56.26|   56.42| 2,094,900|\n",
      "|    max|  153.60|  153.66|  151.66|  152.79|80,898,100|\n",
      "+-------+--------+--------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "summary = df.describe()\n",
    "summary.select(summary['summary'],\n",
    "               format_number(summary['Open'].cast('float'),2).alias('Open'),\n",
    "               format_number(summary['High'].cast('float'),2).alias('High'),\n",
    "               format_number(summary['Low'].cast('float'),2).alias('Low'),\n",
    "               format_number(summary['Close'].cast('float'),2).alias('Close'),\n",
    "               format_number(summary['Volume'].cast('int'),0).alias('Volume')\n",
    "              ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a8eee",
   "metadata": {},
   "source": [
    "# Create a new Dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c47c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hv = df.withColumn('HV Ratio', df['High']/df['Volume']).select(['HV Ratio'])\n",
    "df_hv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8797c7a",
   "metadata": {},
   "source": [
    "# Which day has the peak high in price ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3addd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(df['High'].desc()).select(['Date']).head(1)[0]['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de324d",
   "metadata": {},
   "source": [
    "# What is the mean of the \"Close\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df.select(mean('Close')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a14f16",
   "metadata": {},
   "source": [
    "# What is the maximum and minimum value of the \"Volumn\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "df.select(max('Volume'),min('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba00c8",
   "metadata": {},
   "source": [
    "# How many days did the stocks close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['Close'] < 60).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ffef1",
   "metadata": {},
   "source": [
    "# What percentage of the time was the \"High\" greater than 80 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0794a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['High'] > 80).count() * 100/df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035c018",
   "metadata": {},
   "source": [
    "# What is the Pearson correlation between \"High\" and \"Volume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr('High','Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4130b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "df.select(corr(df['High'], df['Volume'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95cca88",
   "metadata": {},
   "source": [
    "# What is the max \"High\" per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3cf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (dayofmonth, hour, \n",
    "                                   dayofyear, month,\n",
    "                                   year, weekofyear,\n",
    "                                   format_number, date_format)\n",
    "\n",
    "year_df = df.withColumn('Year', year(df['Date']))\n",
    "\n",
    "year_df.groupBy('Year').max()['Year', 'max(High)'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8098a32",
   "metadata": {},
   "source": [
    "# What is the average \"Close\" for each calender month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102af532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column Month from existing Date Column\n",
    "month_df = df.withColumn('Month', month(df['Date']))\n",
    "\n",
    "#Group by month and take average of all other columns\n",
    "month_df = month_df.groupBy('Month').mean()\n",
    "\n",
    "#Sort by month\n",
    "month_df = month_df.orderBy('Month')\n",
    "\n",
    "#Display only month and avg(Close), the desired columns\n",
    "month_df['Month', 'avg(Close)'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32081e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
