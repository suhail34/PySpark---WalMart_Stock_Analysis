{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e876b9ce",
   "metadata": {},
   "source": [
    "# Initialize a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d0993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/10 21:42:05 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('walmart').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e61e23",
   "metadata": {},
   "source": [
    "# Load the Walmart Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd5ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./WMT.xls', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10cfd8d",
   "metadata": {},
   "source": [
    "# Display the Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e0dd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa75f95",
   "metadata": {},
   "source": [
    "# Display the first row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbc1076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date=datetime.datetime(2011, 11, 16, 0, 0), Open=57.099998, High=57.419998, Low=56.639999, Close=56.68, Adj Close=44.899456, Volume=11780800)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b5217",
   "metadata": {},
   "source": [
    "# Check the Schema of the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa78ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659badc6",
   "metadata": {},
   "source": [
    "# Print the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ce3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.datetime(2011, 11, 16, 0, 0), Open=57.099998, High=57.419998, Low=56.639999, Close=56.68, Adj Close=44.899456, Volume=11780800) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 17, 0, 0), Open=56.540001, High=57.189999, Low=56.259998, Close=56.73, Adj Close=44.939064, Volume=10223800) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 18, 0, 0), Open=57.029999, High=57.360001, Low=56.610001, Close=57.23, Adj Close=45.335129, Volume=8982300) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 21, 0, 0), Open=56.93, High=57.290001, Low=56.380001, Close=56.66, Adj Close=44.883606, Volume=9932200) \n",
      "\n",
      "Row(Date=datetime.datetime(2011, 11, 22, 0, 0), Open=56.560001, High=57.130001, Low=56.5, Close=56.849998, Adj Close=45.034107, Volume=7497300) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in df.head(5):\n",
    "    print(line, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a8674",
   "metadata": {},
   "source": [
    "# Print general Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dad8c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------------+------------------+----------------+\n",
      "|summary|              Open|              High|               Low|            Close|         Adj Close|          Volume|\n",
      "+-------+------------------+------------------+------------------+-----------------+------------------+----------------+\n",
      "|  count|              2516|              2516|              2516|             2516|              2516|            2516|\n",
      "|   mean| 90.25209059817178| 90.94377592090628| 89.61924488434002|90.28167732551657| 82.77843126589822|8267158.86327504|\n",
      "| stddev|25.818932768463412|26.070702860968247|25.565153063174236|25.79883827640457|29.207787105719017|4587081.88545677|\n",
      "|    min|         56.389999|              57.0|         56.259998|        56.419998|         44.867764|         2094900|\n",
      "|    max|        153.600006|        153.660004|        151.660004|       152.789993|        151.449997|        80898100|\n",
      "+-------+------------------+------------------+------------------+-----------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f369dd33",
   "metadata": {},
   "source": [
    "# Format Columns to show just 2 Decimal Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3eb1a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+----------+\n",
      "|summary|    Open|    High|     Low|   Close|    Volume|\n",
      "+-------+--------+--------+--------+--------+----------+\n",
      "|  count|2,516.00|2,516.00|2,516.00|2,516.00|     2,516|\n",
      "|   mean|   90.25|   90.94|   89.62|   90.28| 8,267,158|\n",
      "| stddev|   25.82|   26.07|   25.57|   25.80| 4,587,081|\n",
      "|    min|   56.39|   57.00|   56.26|   56.42| 2,094,900|\n",
      "|    max|  153.60|  153.66|  151.66|  152.79|80,898,100|\n",
      "+-------+--------+--------+--------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number\n",
    "\n",
    "summary = df.describe()\n",
    "summary.select(summary['summary'],\n",
    "               format_number(summary['Open'].cast('float'),2).alias('Open'),\n",
    "               format_number(summary['High'].cast('float'),2).alias('High'),\n",
    "               format_number(summary['Low'].cast('float'),2).alias('Low'),\n",
    "               format_number(summary['Close'].cast('float'),2).alias('Close'),\n",
    "               format_number(summary['Volume'].cast('int'),0).alias('Volume')\n",
    "              ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f209cd6",
   "metadata": {},
   "source": [
    "# Create a new Dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257a6501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HV Ratio|\n",
      "+--------------------+\n",
      "| 4.87403215401331E-6|\n",
      "|5.593810422739099E-6|\n",
      "|6.385892366097769E-6|\n",
      "|5.768107871367874E-6|\n",
      "|7.620076694276606E-6|\n",
      "|6.900392232821655E-6|\n",
      "|1.346153893115431...|\n",
      "|6.244549477288143E-6|\n",
      "|5.389564674777206...|\n",
      "|3.974348610998842E-6|\n",
      "|6.731305634267636E-6|\n",
      "|5.265601789429508E-6|\n",
      "|5.564325737979306E-6|\n",
      "|5.175589215548695E-6|\n",
      "|3.757632754877940...|\n",
      "|5.656840767900448E-6|\n",
      "|5.814751314756086E-6|\n",
      "|5.822398800450329...|\n",
      "|5.318033740122675E-6|\n",
      "|6.469134591839006E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hv = df.withColumn('HV Ratio', df['High']/df['Volume']).select(['HV Ratio'])\n",
    "df_hv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a9776",
   "metadata": {},
   "source": [
    "# Which day has the peak high in price ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cbe7cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 12, 1, 0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).select(['Date']).head(1)[0]['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0440ef2",
   "metadata": {},
   "source": [
    "# What is the mean of the \"Close\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6392c0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|90.28167732551657|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df.select(mean('Close')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6fc8ef",
   "metadata": {},
   "source": [
    "# What is the maximum and minimum value of the \"Volumn\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101e3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "df.select(max('Volume'),min('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c03c5d",
   "metadata": {},
   "source": [
    "# How many days did the stocks close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d9787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Close'] < 60).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c16f6",
   "metadata": {},
   "source": [
    "# What percentage of the time was the \"High\" greater than 80 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68457ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.939586645469"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['High'] > 80).count() * 100/df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81575775",
   "metadata": {},
   "source": [
    "# What is the Pearson correlation between \"High\" and \"Volume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc7dd70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07509967259246798"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr('High','Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d621be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  corr(High, Volume)|\n",
      "+--------------------+\n",
      "|-0.07509967259246798|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "df.select(corr(df['High'], df['Volume'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b6428",
   "metadata": {},
   "source": [
    "# What is the max \"High\" per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b3dd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|Year| max(High)|\n",
      "+----+----------+\n",
      "|2018|109.980003|\n",
      "|2015| 90.970001|\n",
      "|2013| 81.370003|\n",
      "|2014| 88.089996|\n",
      "|2019|125.379997|\n",
      "|2020|153.660004|\n",
      "|2012| 77.599998|\n",
      "|2016| 75.190002|\n",
      "|2011|      60.0|\n",
      "|2017|100.129997|\n",
      "|2021|152.570007|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (dayofmonth, hour, \n",
    "                                   dayofyear, month,\n",
    "                                   year, weekofyear,\n",
    "                                   format_number, date_format)\n",
    "\n",
    "year_df = df.withColumn('Year', year(df['Date']))\n",
    "\n",
    "year_df.groupBy('Year').max()['Year', 'max(High)'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053d23f",
   "metadata": {},
   "source": [
    "# What is the average \"Close\" for each calender month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87a5cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|       avg(Close)|\n",
      "+-----+-----------------+\n",
      "|    1|88.47398988177339|\n",
      "|    2|87.60531266666669|\n",
      "|    3|86.47244217050691|\n",
      "|    4|89.30846177403849|\n",
      "|    5|88.39650949999998|\n",
      "|    6|89.40037571361498|\n",
      "|    7|92.05450699530518|\n",
      "|    8|92.63425376018098|\n",
      "|    9|93.86182297536949|\n",
      "|   10| 94.2081447013575|\n",
      "|   11|92.62975491176469|\n",
      "|   12|88.01454553110052|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a new column Month from existing Date Column\n",
    "month_df = df.withColumn('Month', month(df['Date']))\n",
    "\n",
    "#Group by month and take average of all other columns\n",
    "month_df = month_df.groupBy('Month').mean()\n",
    "\n",
    "#Sort by month\n",
    "month_df = month_df.orderBy('Month')\n",
    "\n",
    "#Display only month and avg(Close), the desired columns\n",
    "month_df['Month', 'avg(Close)'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5ec94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
